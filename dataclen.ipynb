{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>Jelek filmnya... apalagi si ernest gak mutu bg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>Film king Arthur ini film paling jelek dari se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@beexkuanlin Sepanjang film gwa berkata kasar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>Ane ga suka fast and furious..menurutku kok je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>@baekhyun36 kan gua ga tau film nya, lu bilang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>positive</td>\n",
       "      <td>Fargo juga adaptasi dari film yang cukup berha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>positive</td>\n",
       "      <td>637.000 waw ini sangat keren flm horor dng jum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>positive</td>\n",
       "      <td>@filmziarah film yang tenang dan menghanyutkan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>positive</td>\n",
       "      <td>Film yg amat menarik. Kisah cinta &amp; kesetiaan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>positive</td>\n",
       "      <td>Nntn @filmziarah , film bagus, ada kali 5 meni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Sentiment                                         Text Tweet\n",
       "0      1  negative  Jelek filmnya... apalagi si ernest gak mutu bg...\n",
       "1      2  negative  Film king Arthur ini film paling jelek dari se...\n",
       "2      3  negative  @beexkuanlin Sepanjang film gwa berkata kasar ...\n",
       "3      4  negative  Ane ga suka fast and furious..menurutku kok je...\n",
       "4      5  negative  @baekhyun36 kan gua ga tau film nya, lu bilang...\n",
       "..   ...       ...                                                ...\n",
       "195  196  positive  Fargo juga adaptasi dari film yang cukup berha...\n",
       "196  197  positive  637.000 waw ini sangat keren flm horor dng jum...\n",
       "197  198  positive  @filmziarah film yang tenang dan menghanyutkan...\n",
       "198  199  positive  Film yg amat menarik. Kisah cinta & kesetiaan ...\n",
       "199  200  positive  Nntn @filmziarah , film bagus, ada kali 5 meni...\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_tweet_sentiment_opini_film.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Jelek filmnya... apalagi si ernest gak mutu bg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Film king Arthur ini film paling jelek dari se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>@beexkuanlin Sepanjang film gwa berkata kasar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Ane ga suka fast and furious..menurutku kok je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>@baekhyun36 kan gua ga tau film nya, lu bilang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>Fargo juga adaptasi dari film yang cukup berha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>637.000 waw ini sangat keren flm horor dng jum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>@filmziarah film yang tenang dan menghanyutkan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>Film yg amat menarik. Kisah cinta &amp; kesetiaan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>Nntn @filmziarah , film bagus, ada kali 5 meni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Sentiment                                         Text Tweet\n",
       "0      1          0  Jelek filmnya... apalagi si ernest gak mutu bg...\n",
       "1      2          0  Film king Arthur ini film paling jelek dari se...\n",
       "2      3          0  @beexkuanlin Sepanjang film gwa berkata kasar ...\n",
       "3      4          0  Ane ga suka fast and furious..menurutku kok je...\n",
       "4      5          0  @baekhyun36 kan gua ga tau film nya, lu bilang...\n",
       "..   ...        ...                                                ...\n",
       "195  196          1  Fargo juga adaptasi dari film yang cukup berha...\n",
       "196  197          1  637.000 waw ini sangat keren flm horor dng jum...\n",
       "197  198          1  @filmziarah film yang tenang dan menghanyutkan...\n",
       "198  199          1  Film yg amat menarik. Kisah cinta & kesetiaan ...\n",
       "199  200          1  Nntn @filmziarah , film bagus, ada kali 5 meni...\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"] = df[\"Sentiment\"].map({\"positive\":1, \"negative\":0})\n",
    "   \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]\n",
      "\n",
      " [[13 14]\n",
      "  [15 16]]]\n",
      "[[[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 14]]\n",
      "\n",
      " [[ 3  4]\n",
      "  [ 7  8]\n",
      "  [11 12]\n",
      "  [15 16]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [[1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12],\n",
    "    [13,14,15,16]]\n",
    "x = np.array(x)\n",
    "reshape1 = x.reshape(x.shape[0], 2, 2)\n",
    "reshape = reshape.transpose(1,0,2)\n",
    "print(x)\n",
    "print(reshape1)\n",
    "print(reshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp = np.exp(x)\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Feedforward(x):\n",
    "    matmul = np.matmul\n",
    "    x = np.array(x)\n",
    "    dx = x.shape[1]\n",
    "    dx = dx *4\n",
    "    w1 = np.random.randn(len(x[0]),dx)\n",
    "    b1 = np.random.randn(len(x[0]),dx)\n",
    "    Logits = matmul(x, w1) + b1\n",
    "    belah = Logits.shape[1]//2\n",
    "    x1 = Logits[:,:belah]\n",
    "    x2 = Logits[:,belah:]\n",
    "    Logits = SwingGlu(x1,x2)\n",
    "    w2 = np.random.randn(*Logits.shape)\n",
    "    b2 = np.random.randn()\n",
    "    linear = matmul(Logits, w2.T) + b2\n",
    "    output = linear\n",
    "    return output\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def swish(x):\n",
    "    return x * sigmoid(x)    \n",
    "def SwingGlu(x1,x2):\n",
    "    return  x2 * swish(x1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [[1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12],\n",
    "    [13,14,15,16]]\n",
    "x= np.array(x)\n",
    "dx = x.shape[1]\n",
    "\n",
    "print(Feedforward(x).shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'jelek'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, kata \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(token[i]):\n\u001b[0;32m     45\u001b[0m         batas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(kata), max_len\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m         \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mbatas\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m kata[:batas]\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# for i, text in enumerate(token):\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m#     print(i, text)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'jelek'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "def embedding_matriks(vocab, d):\n",
    "    embedding = {} \n",
    "    for kata in vocab:\n",
    "        embedding[kata] = np.random.randn(d)\n",
    "    return embedding\n",
    "\n",
    "def tokenize(texts):\n",
    "    vocab = set()\n",
    "    for text in texts:\n",
    "        vocab.update(text.split())\n",
    "    vocab = list(vocab)\n",
    "    vocab_size = len(vocab)\n",
    "    tokenized_texts = []\n",
    "    for text in texts:\n",
    "        tokens = tokens.split()\n",
    "        tokenized_texts.append(tokens)\n",
    "    return vocab, tokenized_texts\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "data = pd.read_csv(\"file_baru.csv\")\n",
    "data[\"Clean\"] = data[\"Text Tweet\"].apply(clean_text) \n",
    "texts = data[\"Clean\"].tolist()\n",
    "labels =  data[\"Sentiment\"].tolist()\n",
    "d = 512\n",
    "\n",
    "\n",
    "token = []\n",
    "for i in texts:\n",
    "    token.append(i.split())\n",
    "panjang_kalimat = []\n",
    "for i in token:\n",
    "    panjang_kalimat.append(len(i))\n",
    "max_len = max(len_token)\n",
    "\n",
    "x = np.zeros((len(texts), max_len), dtype=int)\n",
    "for i , kalimat in enumerate(token):\n",
    "    for j, kata in enumerate(token[i]):\n",
    "        batas = min(len(kata), max_len)\n",
    "        x[i, :batas] = kata[:batas]\n",
    "print(x)\n",
    "    \n",
    "    \n",
    "   \n",
    "# for i, text in enumerate(token):\n",
    "#     print(i, text)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('a', 'k', 'u', '</w>'): 1}\n",
      "{('a', 'k', 'u', '</w>'): 1, ('s', 'u', 'k', 'a', '</w>'): 1}\n",
      "{('a', 'k', 'u', '</w>'): 1, ('s', 'u', 'k', 'a', '</w>'): 1, ('m', 'a', 'k', 'a', 'n', '</w>'): 1}\n",
      "{('a', 'k', 'u', '</w>'): 1, ('s', 'u', 'k', 'a', '</w>'): 1, ('m', 'a', 'k', 'a', 'n', '</w>'): 1, ('n', 'a', 's', 'i', '</w>'): 1}\n",
      "{('a', 'k', 'u', 's', 'u', 'k', 'a', 'm', 'a', 'k', 'a', 'n', 'n', 'a', 's', 'i'): 1, ('d', 'i', 'a', '</w>'): 1}\n",
      "{('a', 'k', 'u', 's', 'u', 'k', 'a', 'm', 'a', 'k', 'a', 'n', 'n', 'a', 's', 'i'): 1, ('d', 'i', 'a', '</w>'): 1, ('s', 'u', 'k', 'a', '</w>'): 1}\n",
      "{('a', 'k', 'u', 's', 'u', 'k', 'a', 'm', 'a', 'k', 'a', 'n', 'n', 'a', 's', 'i'): 1, ('d', 'i', 'a', '</w>'): 1, ('s', 'u', 'k', 'a', '</w>'): 1, ('m', 'a', 'k', 'a', 'n', '</w>'): 1}\n",
      "{('a', 'k', 'u', 's', 'u', 'k', 'a', 'm', 'a', 'k', 'a', 'n', 'n', 'a', 's', 'i'): 1, ('d', 'i', 'a', '</w>'): 1, ('s', 'u', 'k', 'a', '</w>'): 1, ('m', 'a', 'k', 'a', 'n', '</w>'): 1, ('a', 'y', 'a', 'm', '</w>'): 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = {} \n",
    "for i in corpus:\n",
    "        for j in i: \n",
    "            chars = list(j) + ['</w>'] \n",
    "            token_tuple = tuple(chars) \n",
    "            if token_tuple in vocab: \n",
    "                vocab[token_tuple] += 1\n",
    "            else:\n",
    "                vocab[token_tuple] = 1 \n",
    "                print(vocab)\n",
    "    \n",
    "                \n",
    "    # while True:\n",
    "        new_vocab = {}\n",
    "        pair_freq = {} \n",
    "        for token, freq in vocab.items():   \n",
    "            for i in range(len(token)-1):  \n",
    "                pair = (token[i], token[i+1]) \n",
    "                if pair in pair_freq: \n",
    "                    pair_freq[pair] += freq\n",
    "                else:\n",
    "                    pair_freq[pair] = freq\n",
    "        \n",
    "        best_pair  = max(pair_freq, key=pair_freq.get )\n",
    "       \n",
    "        new_token = []\n",
    "        for token, freq in list(vocab.items()):\n",
    "            for i in range(len(token)-1):\n",
    "\n",
    "                npair =  token[i] + token[i+1]\n",
    "                if npair == best_pair:\n",
    "                    new_token.append(npair)\n",
    "                else :\n",
    "                    new_token.append(token[i])\n",
    "\n",
    "        new_token = tuple(new_token)\n",
    "        new_vocab[new_token] = freq\n",
    "        vocab = new_vocab\n",
    "        del new_vocab\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "                   \n",
    "                   \n",
    "               \n",
    "                    \n",
    "                    \n",
    "\n",
    "                \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('ak',): 0, ('aku',): 1, ('aku', '</w>'): 2, ('s',): 3, ('su',): 4, ('suk',): 5, ('suka',): 6, ('suka', '</w>'): 7, ('d',): 8, ('di',): 9, ('dim',): 10, ('dima',): 11, ('dima', 'n'): 12, ('dimana',): 13, ('dimana', '</w>'): 14, ('n',): 15, ('na',): 16, ('nas',): 17, ('nasi',): 18, ('nasi</w>',): 19, ('dim', 'ak'): 20, ('dim', 'aka'): 21, ('dimakan',): 22, ('dimakan', '</w>'): 23, ('a',): 24, ('ay',): 25, ('aya',): 26, ('ayam',): 27, ('ayam', '</w>'): 28, ('m',): 29, ('mak',): 30, ('maka',): 31, ('makan',): 32, ('makan</w>',): 33, ('dime',): 34, ('dimej',): 35, ('dimeja',): 36, ('dimeja', '</w>'): 37}\n",
      "[['aku', 'suka', 'dimana', 'nasi'], ['nasi', 'dimakan', 'ayam'], ['makan', 'dimeja', 'makan']]\n"
     ]
    }
   ],
   "source": [
    "corpus = [[\"aku\", \"suka\", \"dimana\", \"nasi\"], [\"nasi\", \"dimakan\", \"ayam\"], [\"makan\", \"dimeja\" ,\"makan\"]]\n",
    "def tokenizer(corpus):\n",
    "    vocab = {}\n",
    "    for kalimat in corpus:\n",
    "        for kata in kalimat:\n",
    "            char = list(kata) + [\"</w>\"]\n",
    "            char = tuple(char)\n",
    "            if char in vocab:\n",
    "                vocab[char] += 1\n",
    "            else:\n",
    "                vocab[char] = 1\n",
    "    while True:\n",
    "        pair_freq = {}\n",
    "        for token, freq in vocab.items():\n",
    "            for i in range(len(token) - 1):\n",
    "                pair = (token[i], token[i+1])\n",
    "                if pair in pair_freq:\n",
    "                    pair_freq[pair] += freq\n",
    "                else:\n",
    "                    pair_freq[pair] = freq\n",
    "        best_value = max(pair_freq.values())\n",
    "        best_pair = max(pair_freq, key=pair_freq.get)\n",
    "\n",
    "        if best_value < 2:\n",
    "            break\n",
    "\n",
    "        new_vocab = {}\n",
    "        for token, freq in vocab.items():\n",
    "            new_token = []\n",
    "            i = 0\n",
    "            while i < len(token):\n",
    "                if i < len(token) - 1 and (token[i], token[i+1]) == best_pair:\n",
    "                    new_token.append(token[i] + token[i+1])\n",
    "                    new_vocab[tuple(new_token)] = freq\n",
    "                    i += 2\n",
    "\n",
    "                else:\n",
    "                    new_token.append(token[i])\n",
    "                    i += 1\n",
    "                new_vocab[tuple(new_token)] = freq\n",
    "\n",
    "        vocab = new_vocab\n",
    "        vocab_index = {}\n",
    "        for i, token in enumerate(vocab.keys()):\n",
    "            vocab_index[token] = i\n",
    "        \n",
    "    return vocab_index\n",
    "\n",
    "    \n",
    "vocab = tokenizer(corpus)\n",
    "\n",
    "print(vocab)\n",
    "print(corpus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'</w>': 0, 'a': 1, 'ak': 2, 'aka': 3, 'aku': 4, 'ay': 5, 'aya': 6, 'ayam': 7, 'd': 8, 'di': 9, 'dim': 10, 'dima': 11, 'dimakan': 12, 'dimana': 13, 'dime': 14, 'dimej': 15, 'dimeja': 16, 'm': 17, 'mak': 18, 'maka': 19, 'makan': 20, 'makan</w>': 21, 'n': 22, 'na': 23, 'nas': 24, 'nasi': 25, 'nasi</w>': 26, 's': 27, 'su': 28, 'suk': 29, 'suka': 30, '[UNK]': 31}\n"
     ]
    }
   ],
   "source": [
    "def flatten_vocab(vocab):\n",
    "    token_set = set()\n",
    "    for token_tuple in vocab.keys():\n",
    "        for t in token_tuple:\n",
    "            token_set.add(t)\n",
    "            \n",
    "    vocab_dict = {token: idx for idx, token in enumerate(sorted(token_set))}\n",
    "    vocab_dict[\"[UNK]\"] = len(vocab_dict)  # optional: token unknown\n",
    "    return vocab_dict\n",
    "\n",
    "vocab_dict = flatten_vocab(vocab)\n",
    "print(vocab_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aku', 'suka', 'dimana', 'nasi'], ['nasi', 'dimakan', 'ayam'], ['makan', 'dimeja', 'makan']]\n",
      "{'</w>': 0, 'a': 1, 'ak': 2, 'aka': 3, 'aku': 4, 'ay': 5, 'aya': 6, 'ayam': 7, 'd': 8, 'di': 9, 'dim': 10, 'dima': 11, 'dimakan': 12, 'dimana': 13, 'dime': 14, 'dimej': 15, 'dimeja': 16, 'm': 17, 'mak': 18, 'maka': 19, 'makan': 20, 'makan</w>': 21, 'n': 22, 'na': 23, 'nas': 24, 'nasi': 25, 'nasi</w>': 26, 's': 27, 'su': 28, 'suk': 29, 'suka': 30, '[UNK]': 31}\n",
      "[[4, 0, 30, 0, 13, 0, 26], [26, 11, 31, 1, 22, 0, 7, 0], [21, 16, 0, 21]]\n",
      "tensor([[ 4,  0, 30,  0, 13,  0, 26,  0],\n",
      "        [26, 11, 31,  1, 22,  0,  7,  0],\n",
      "        [21, 16,  0, 21,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def encode_word(word, vocab_dict):\n",
    "    tokens = list(word) + [\"</w>\"]\n",
    "    while True:\n",
    "        merged = False\n",
    "        for i in range(len(tokens)-1):\n",
    "            pair = tokens[i] + tokens[i+1]\n",
    "            if pair in vocab_dict:\n",
    "                tokens = tokens[:i] + [pair] + tokens[i+2:]\n",
    "                merged = True\n",
    "                break\n",
    "        if not merged:\n",
    "            break\n",
    "\n",
    "    token_ids = []\n",
    "    for t in tokens:\n",
    "        if t in vocab_dict:\n",
    "            token_ids.append(vocab_dict[t])\n",
    "        else:\n",
    "            for c in t:\n",
    "                if c in vocab_dict:\n",
    "                    token_ids.append(vocab_dict[c])\n",
    "                else:\n",
    "                    token_ids.append(vocab_dict['[UNK]'])\n",
    "    return token_ids\n",
    "\n",
    "def encode_corpus(corpus, vocab_dict):\n",
    "    encoded = []\n",
    "    for sentence in corpus:\n",
    "        encoded_sentence = []\n",
    "        for word in sentence:\n",
    "            encoded_sentence.extend(encode_word(word, vocab_dict))\n",
    "        encoded.append(encoded_sentence)\n",
    "    return encoded\n",
    "\n",
    "# contoh corpus\n",
    "token = encode_corpus(corpus, vocab_dict)\n",
    "print(corpus)\n",
    "print(vocab_dict)\n",
    "max_len = len(max(token))\n",
    "print(token)\n",
    "\n",
    "\n",
    "\n",
    "    # ubah list jadi tensor satu per satu\n",
    "tensor_token = [torch.tensor(seq) for seq in token]\n",
    "\n",
    "# padding jadi batch tensor\n",
    "padded_batch = pad_sequence(tensor_token, batch_first=True, padding_value=0)\n",
    "\n",
    "print(padded_batch)\n",
    "d = 64\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     embedding_matriks \u001b[38;5;241m=\u001b[39m embedding[batch]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding_matriks \n\u001b[1;32m---> 13\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mword_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_matriks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(embedding)\n",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m, in \u001b[0;36mword_embedding\u001b[1;34m(token, embedding)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_embedding\u001b[39m(token, embedding):\n\u001b[1;32m---> 10\u001b[0m     embedding_matriks \u001b[38;5;241m=\u001b[39m embedding[\u001b[43mbatch\u001b[49m]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding_matriks\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def embedding_matriks(vocab, d):\n",
    "    embedding = np.array(np.random.randn(len(vocab), d))\n",
    "    return embedding\n",
    "\n",
    "e_matriks = embedding_matriks(vocab_dict, d)\n",
    "print(e_matriks.shape)\n",
    "\n",
    "def word_embedding(batch_size, len_token, e_matriks):\n",
    "    embedding_matriks = embedding[batch]\n",
    "    return embedding_matriks \n",
    "\n",
    "embedding = word_embedding(padded_batch, e_matriks)\n",
    "print(embedding)\n",
    "\n",
    "Z\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def isPalindrome (x: int):\n",
    "       yam =list(str(x))\n",
    "       yam = [int(i) for i in yam ]\n",
    "       for i in (yam):\n",
    "        print(-i-1)\n",
    "        if yam[i] == yam[-i-1]:\n",
    "         return True\n",
    "        else:\n",
    "         return False\n",
    "       \n",
    "       \n",
    "\n",
    "\n",
    "x = 121\n",
    "x = isPalindrome(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def romanToInt(s: str) -> int:\n",
    "    roman = { 'I':1, 'V':5, 'X':10, 'L':50, 'C':100, 'D':500, 'M':1000}\n",
    "\n",
    "    total = 0\n",
    "    prev = 0\n",
    "    for i in reversed(s):\n",
    "        curr = roman[i]\n",
    "        if curr < prev:\n",
    "            total -= curr\n",
    "        else:\n",
    "            total += curr\n",
    "        prev = curr\n",
    "\n",
    "    return total \n",
    "            \n",
    "                \n",
    "        \n",
    "                \n",
    "    \n",
    "S = \"VIII\"\n",
    "chi = romanToInt(S)\n",
    "print(chi)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "ABCD\n"
     ]
    }
   ],
   "source": [
    "s = \"ABCD\"\n",
    "for i in (s):\n",
    "    print(i)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def isValid( s: str) -> bool:\n",
    "    pair = {')': '(', ']': '[', '}': '{'}\n",
    "    total = []\n",
    "    for i in s:\n",
    "        if i == '(' or i == '{' or i == '[':\n",
    "            total.append(i)\n",
    "        elif i == ')' or i == '}' or i == ']':\n",
    "            if total[-1]  == pair[i]:\n",
    "                total.pop()\n",
    "            else:\n",
    "                return False\n",
    "    if len(total) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "                \n",
    "\n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "s = \"[\"\n",
    "C = isValid(s)\n",
    "print(C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olleh\n",
      "['o', 'l', 'l', 'e', 'h']\n",
      "['o', 'l', 'l', 'e', 'h']\n"
     ]
    }
   ],
   "source": [
    "def reverseString( s: [str]) -> None:\n",
    "        ayam = \"\".join(reversed(s))\n",
    "        chik = []\n",
    "        print(ayam)\n",
    "        for i in ayam:\n",
    "            chik.append(i)\n",
    "        print(chik)\n",
    "        return chik\n",
    "    \n",
    "s= [\"h\",\"e\",\"l\",\"l\",\"o\"]\n",
    "print(reverseString(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m [[ \u001b[38;5;241m709\u001b[39m,  \u001b[38;5;241m503\u001b[39m,  \u001b[38;5;241m114\u001b[39m, \u001b[38;5;241m1318\u001b[39m,  \u001b[38;5;241m480\u001b[39m, \u001b[38;5;241m1358\u001b[39m,  \u001b[38;5;241m523\u001b[39m,  \u001b[38;5;241m981\u001b[39m,  \u001b[38;5;241m227\u001b[39m,   \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m1043\u001b[39m,  \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1224\u001b[39m,   \u001b[38;5;241m41\u001b[39m,\n\u001b[0;32m      2\u001b[0m      \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m1073\u001b[39m, \u001b[38;5;241m1356\u001b[39m, \u001b[38;5;241m1462\u001b[39m,  \u001b[38;5;241m214\u001b[39m, \u001b[38;5;241m1429\u001b[39m,  \u001b[38;5;241m367\u001b[39m, \u001b[38;5;241m1354\u001b[39m,  \u001b[38;5;241m227\u001b[39m,  \u001b[38;5;241m947\u001b[39m,   \u001b[38;5;241m12\u001b[39m,  \u001b[38;5;241m840\u001b[39m,   \u001b[38;5;241m12\u001b[39m,    \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     30\u001b[0m      \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m,    \u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[42 35 17 39 31 68 94 76 33 70 95  4 74 59 67  7]\n",
      "  [ 1 71 54 67 47 80 80 97 72 62 56 38 96  7 12  1]\n",
      "  [19 81 74 17 32 72 77 49 13  1 73 61 49 39  0 37]\n",
      "  [72  0 67 76 26 67 23  0 70 95 27 27 95 29 24 29]\n",
      "  [35 51 30 32 80 75 56  0 31 11 84 26 52  2 96 82]\n",
      "  [ 1 58 62 95 80 18 40 28 18 97 52 54 18 21  4 69]\n",
      "  [10 20 20 86 16 17 13 76  6 93 55 70 44 68 47 22]\n",
      "  [83 58 82 76 78 59 49 78 60 13 30 43 23 61 20 98]]\n",
      "\n",
      " [[78 27 14 99 32 61 28  9 40 92 74 20 42 59 81 58]\n",
      "  [91 65 56 57 46 48  6 88 59 56  0 31 53 99 51 35]\n",
      "  [10 12 70 80 51 94 25  1 82 75 48 77 63 68 41 22]\n",
      "  [34 59 97 11 65 59 13 72 78 40  0 73 90 97 13 41]\n",
      "  [23 44 47 13 89 76 85 27 90 97 37 96 64 19 38 60]\n",
      "  [99 49 42 23 33  0 34 93 55 88 61 25 47 15 59 38]\n",
      "  [89 47 86 30 69 81 15 34 15 64 83 74 32 20 84 26]\n",
      "  [74 35 73 93 30 57 57 19 93 99 16 82 80 12 51 16]]\n",
      "\n",
      " [[98 43 56 65  7 45 24 42  7 58 59 54  6 95 65 61]\n",
      "  [50 17 17 14 16 95 71 69 70 69 97 69 39  6 33 86]\n",
      "  [93 45 69 30 63 47 11 58 64 33 32 56 48 11 54 12]\n",
      "  [17 82 90 86 35 65 44 70 84 49 63  4 57 20 27  4]\n",
      "  [64 32 59 21 31 94 92 65 22  8 15 86 21 45 81 21]\n",
      "  [36 70 30 82 89 69  9 32 34 18  5 94 62 13 64 63]\n",
      "  [85 80 12 74 56 95 91 86 59 75 57  7 83  2 43 67]\n",
      "  [24 70 87 15 61 41 14 83 14 61 20 63 40 57 18 26]]\n",
      "\n",
      " [[97 22 94 44 28 25 29 19  1 58 33  5 34  3 19 11]\n",
      "  [84 77 68 38 72 61  1  5  7 44 86 54 29  2 59 27]\n",
      "  [85 95 62 36 89 93 82 15 51  1 21 82 38 41 29 62]\n",
      "  [45 35 77 27  2 37  6 46 12 35  0 25 31 49 37 63]\n",
      "  [27 87 13 95  0 35 41 34 93 49 92 48 35 42 44  9]\n",
      "  [69 92 93 63 45 71 81 16 17  0 77 75 89 85 67 89]\n",
      "  [57 61 73 62 84 70 70  3 13 93 56 18 23  9 96 44]\n",
      "  [72 70 37 40 38 52 23 66 16 93 78 95 10 96 13 64]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dummy_data = np.random.randint(0, 100, size=(4, 8, 16))\n",
    "print(dummy_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 4, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w= np.random.rand(*dummy_data.shape)\n",
    "w = w.reshape(4,8,4,4)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rope(x):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMHSA(x,d, num_head = 4, head_dim = 8, num_group = 2):\n",
    "    wq = np.random.randn(d,d)\n",
    "    wk = np.random.rand(d,d)\n",
    "    wv = np.random.rand(d,d)\n",
    "\n",
    "    Q = x @ wq.T \n",
    "    K = x @ wk.T\n",
    "    V = x @ wv.T\n",
    "\n",
    "    Q = Q.reshape(10,36,2,4,8).transpose(0,2,1,3,4)\n",
    "    K = K.reshape(10,36,2,4,8).transpose(0,2,1,3,4)\n",
    "    V = V.reshape(10,36,2,4,8).transpose(0,2,1,3,4)\n",
    "    \n",
    "    Q = rope(Q, dims= 2)\n",
    "    K = rope(K,dims= 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
